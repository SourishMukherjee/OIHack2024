{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T07:46:25.682596Z",
     "start_time": "2024-01-07T07:46:21.688303Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from htmlTemplates import css, bot_template, user_template\n",
    "from langchain_community.vectorstores.elasticsearch import ElasticsearchStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import PyPDF2\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from langchain_community.llms import WatsonxLLM\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain.prompts import PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b513f0bbb83996e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:24:06.281695Z",
     "start_time": "2024-01-07T10:24:06.277326Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "es_model_id = '.elser_model_2_linux-x86_64'\n",
    "index_name = \"elser_index_vb_13\"\n",
    "llm_model_id = \"meta-llama/llama-2-13b-chat\"\n",
    "wx_url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "wx_project_id = \"b33db82c-437e-4d87-8b9c-719e9919003e\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baca43d8373c642a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:44:17.707960Z",
     "start_time": "2024-01-07T10:44:17.702373Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template =\"\"\"[INST]You are a helpful, respectful, and honest assistant. Always answer as helpfully as possible, while being safe. Be brief in your answers. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.If you don\\\\'\\''t know the answer to a question, please do not share false information. \\n Answer with no more than 150 words, in 2 or 3 sentences. If you cannot base your answer on the given document, please state that you do not have an answer.\\n\\n{question} Answer with no more than 200 words. If you cannot base your answer on the given document, please state that you do not have an answer. do not include a question in your response. dont prompt to make select correct answers[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e14a3a567b32d9f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "template = \"\"\"You are a helpful, respectful, and honest assistant. Always answer as helpfully as possible, while being safe. Be brief in your answers. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "    If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don\\'''t know the answer to a question, please do not share false information.\n",
    "    Answer with no more than 150 words. If you cannot base your answer on the given document, please state that you do not have an answer.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e49bddd35c6d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T08:05:12.765779Z",
     "start_time": "2024-01-07T08:05:12.763477Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_docs(pdf_docs):\n",
    "    docs = []\n",
    "    metadata = []\n",
    "    content = []\n",
    "\n",
    "    for pdf in pdf_docs:\n",
    "\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf)\n",
    "        for index, text in enumerate(pdf_reader.pages):\n",
    "            doc_page = {'title': pdf + \" page \" + str(index + 1),\n",
    "                        'content': pdf_reader.pages[index].extract_text()}\n",
    "            docs.append(doc_page)\n",
    "    for doc in docs:\n",
    "        content.append(doc[\"content\"])\n",
    "        metadata.append({\n",
    "            \"title\": doc[\"title\"]\n",
    "        })\n",
    "    return content, metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e8895acb436e94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T07:47:25.155847Z",
     "start_time": "2024-01-07T07:47:25.149629Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_text_chunks(content, metadata):\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=512,\n",
    "        chunk_overlap=256,\n",
    "    )\n",
    "    split_docs = text_splitter.create_documents(content, metadatas=metadata)\n",
    "    print(f\"Split documents into {len(split_docs)} passages\")\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956e5ad8704a563f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T07:47:34.333240Z",
     "start_time": "2024-01-07T07:47:34.330872Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ingest_and_get_vector_store(split_docs):\n",
    "    vector_store = ElasticsearchStore(\n",
    "        es_url=os.environ[\"elastic_search_url\"],\n",
    "        es_api_key=os.environ[\"elastic_search_api_key\"],\n",
    "        index_name=index_name,\n",
    "        strategy=ElasticsearchStore.SparseVectorRetrievalStrategy(model_id=es_model_id)\n",
    "    )\n",
    "    documents = vector_store.from_documents(\n",
    "        split_docs,\n",
    "        es_url=os.environ[\"elastic_search_url\"],\n",
    "        es_api_key=os.environ[\"elastic_search_api_key\"],\n",
    "        index_name=index_name,\n",
    "        strategy=ElasticsearchStore.SparseVectorRetrievalStrategy(model_id=es_model_id)\n",
    "    )\n",
    "\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daeb1adc421d294e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T07:48:11.383224Z",
     "start_time": "2024-01-07T07:48:11.380239Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_conversation_chain(vector_store):\n",
    "    parameters = {\n",
    "        GenParams.DECODING_METHOD: \"sample\",\n",
    "        GenParams.MAX_NEW_TOKENS: 100,\n",
    "        GenParams.MIN_NEW_TOKENS: 1,\n",
    "        GenParams.TEMPERATURE: 0.5,\n",
    "        GenParams.TOP_K: 50,\n",
    "        GenParams.TOP_P: 1,\n",
    "    }\n",
    "\n",
    "    watsonx_llm = WatsonxLLM(\n",
    "        model_id=llm_model_id,\n",
    "        url=wx_url,\n",
    "        project_id=wx_project_id,\n",
    "        params=parameters,\n",
    "        apikey=os.environ[\"WATSONX_APIKEY\"]\n",
    "    )\n",
    "    retriever = vector_store.as_retriever()\n",
    "    CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history', return_messages=True, output_key='answer')\n",
    "\n",
    "    conversation_chain = (ConversationalRetrievalChain.from_llm\n",
    "                          (llm=watsonx_llm,\n",
    "                           retriever=retriever,\n",
    "                           condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n",
    "                           memory=memory,\n",
    "                           return_source_documents=True))\n",
    "    return conversation_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d0cc0f87a9595c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T07:48:35.893137Z",
     "start_time": "2024-01-07T07:48:35.887077Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def validate_answer_against_sources(response_answer, source_documents):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    similarity_threshold = 0.5  # Example threshold\n",
    "    source_texts = [doc.page_content for doc in source_documents]\n",
    "\n",
    "    answer_embedding = model.encode(response_answer, convert_to_tensor=True)\n",
    "    source_embeddings = model.encode(source_texts, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    cosine_scores = util.pytorch_cos_sim(answer_embedding, source_embeddings)\n",
    "\n",
    "    # Check if the similarity score for any document exceeds the threshold\n",
    "    if any(score.item() > similarity_threshold for score in cosine_scores[0]):\n",
    "        return True  # The answer has enough in common with at least one source document\n",
    "\n",
    "    return False  # If no document is similar enough, consider the answer not validated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e435e003cfe91c1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:24:11.041141Z",
     "start_time": "2024-01-07T10:24:10.938343Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split documents into 3 passages\n"
     ]
    }
   ],
   "source": [
    "pdf_docs=[\"Industry accelerators - IBM Documentation.pdf\"]\n",
    "content, metadata = prepare_docs(pdf_docs)\n",
    "split_docs = get_text_chunks(content, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f714b5f5df09e897",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:24:13.506700Z",
     "start_time": "2024-01-07T10:24:12.199767Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorstore = ingest_and_get_vector_store(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79d503befc592a5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:44:24.130465Z",
     "start_time": "2024-01-07T10:44:22.503570Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conversation_chain=get_conversation_chain(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e29e53d12e7fc69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:44:48.413312Z",
     "start_time": "2024-01-07T10:44:48.408816Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_question = \"who is vikram bhat?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0c000474595b40e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:44:54.014449Z",
     "start_time": "2024-01-07T10:44:50.322823Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Vikram Bhat is not mentioned in the provided document, therefore, there is no answer.\n"
     ]
    }
   ],
   "source": [
    "response=conversation_chain({\"question\": user_question})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "185c23b841a7cfae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T10:44:57.591045Z",
     "start_time": "2024-01-07T10:44:57.442686Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry I can not answer the question based on the given documents\n"
     ]
    }
   ],
   "source": [
    "if response['source_documents']:\n",
    "    response_answer = response['answer']\n",
    "    source_docs = response['source_documents']\n",
    "\n",
    "    # Post-processing step to validate the answer against the source documents\n",
    "    is_valid_answer = validate_answer_against_sources(response_answer, source_docs)\n",
    "    if not is_valid_answer:\n",
    "        response['answer'] = \"Sorry I can not answer the question based on the given documents\"\n",
    "else:\n",
    "    response['answer'] =\"Sorry, I cannot answer the question based on the given documents\"\n",
    "\n",
    "print(response['answer'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6171c3ec003c5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
